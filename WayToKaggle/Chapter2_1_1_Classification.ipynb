{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.1.1 线性分类器\n",
    "##### 良性/恶性肿瘤预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(683, 11)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 3
    }
   ],
   "source": [
    "columns_names = ['Sample code number', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape', 'Marginal Adhesion', \n",
    "                'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses', 'Class']\n",
    "\n",
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data',\n",
    "                   names=columns_names)\n",
    "# 替换缺失值\n",
    "data = data.replace(to_replace='?', value=np.nan)\n",
    "data = data.dropna(how='any')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    344\n",
       "4    168\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用sklearn.cross_valiation里的train_test_split模块分割数据\n",
    "# 随机采样25%的数据用于测试，75%用于训练\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[columns_names[1:10]], data[columns_names[10]],\n",
    "                                                    test_size=0.25, random_state=33)\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    100\n",
       "4     71\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用线性分类模型对良性/恶性肿瘤预测分类\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标准化数据，保证每个维度的特征数据方差为1，均值为0.使预测结果不会被某些维度过大的特征值而主导。\n",
    "# fit_transform方法是fit和transform的结合，fit_transform(X_train) 意思是找出X_train的@和@，并应用在X_train上。\n",
    "# 这时对于X_test，我们就可以直接使用transform方法。因为此时StandardScaler已经保存了X_train的@和@。\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化LogisticRegression与SGDClassifier\n",
    "lr = LogisticRegression(solver='liblinear')\n",
    "sgdc = SGDClassifier()\n",
    "# 利用lr训练\n",
    "lr.fit(X_train, y_train)\n",
    "lr_y_predict = lr.predict(X_test)\n",
    "# 利用sgdc训练\n",
    "sgdc.fit(X_train, y_train)\n",
    "sgdc_y_predict = sgdc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 4, 4, 2, 2, 2, 4, 2, 2, 2, 2, 4, 2, 4, 4, 4, 4, 4, 2, 2, 4,\n",
       "       4, 2, 4, 4, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 2, 4,\n",
       "       2, 2, 4, 2, 2, 4, 4, 2, 2, 2, 4, 2, 2, 2, 2, 2, 4, 4, 2, 2, 2, 4,\n",
       "       2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 4, 4, 2, 2, 2, 4, 2, 2, 2, 4, 2,\n",
       "       4, 2, 4, 4, 2, 2, 2, 2, 4, 4, 2, 2, 2, 4, 2, 2, 4, 2, 2, 2, 2, 2,\n",
       "       4, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 4, 2, 4, 2, 2, 2, 4, 2, 2, 4, 4,\n",
       "       2, 4, 4, 2, 2, 2, 2, 4, 2, 4, 2, 4, 2, 2, 2, 2, 2, 4, 4, 2, 4, 4,\n",
       "       2, 4, 2, 2, 2, 2, 4, 4, 4, 2, 4, 2, 2, 4, 2, 4, 4])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 2, 4, 4, 2, 2, 2, 4, 2, 2, 2, 2, 4, 2, 2, 2, 4, 2, 4, 2, 2, 4,\n",
       "       4, 2, 2, 4, 2, 2, 4, 2, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 4, 4, 2, 4,\n",
       "       2, 2, 4, 2, 2, 4, 4, 2, 2, 2, 4, 2, 2, 2, 2, 2, 4, 4, 2, 2, 2, 4,\n",
       "       2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 4, 2, 2, 2, 4, 2,\n",
       "       4, 2, 2, 4, 2, 2, 2, 2, 4, 2, 2, 2, 2, 4, 2, 2, 4, 2, 2, 2, 2, 2,\n",
       "       4, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 4, 2, 2, 2, 4, 2, 2, 4, 4,\n",
       "       2, 4, 4, 2, 2, 2, 2, 4, 2, 4, 2, 4, 2, 2, 2, 2, 2, 4, 4, 2, 4, 4,\n",
       "       2, 4, 2, 2, 2, 2, 4, 4, 4, 2, 4, 2, 2, 4, 2, 4, 4])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgdc_y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用线性分类模型对良性/恶性肿瘤的性能分析\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LR Classifier: 0.9883040935672515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       0.99      0.99      0.99       100\n",
      "   Malignant       0.99      0.99      0.99        71\n",
      "\n",
      "    accuracy                           0.99       171\n",
      "   macro avg       0.99      0.99      0.99       171\n",
      "weighted avg       0.99      0.99      0.99       171\n",
      "\n",
      "Accuracy of SGDC Classifier: 0.9298245614035088\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       0.90      0.99      0.94       100\n",
      "   Malignant       0.98      0.85      0.91        71\n",
      "\n",
      "    accuracy                           0.93       171\n",
      "   macro avg       0.94      0.92      0.93       171\n",
      "weighted avg       0.93      0.93      0.93       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 利用lr\n",
    "# 测试lr模型在测试集上的准确性结果\n",
    "print('Accuracy of LR Classifier:', lr.score(X_test, y_test))\n",
    "# 获得LR的召回率、准确率和F1指标\n",
    "print(classification_report(y_test, lr_y_predict, target_names=['Benign', 'Malignant']))\n",
    "\n",
    "# 利用sgdc\n",
    "print('Accuracy of SGDC Classifier:', sgdc.score(X_test, y_test))\n",
    "print(classification_report(y_test, sgdc_y_predict, target_names=['Benign', 'Malignant']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.1.2 支持向量机（分类）\n",
    "##### 使用支持向量机分类器处理Scikit-learn内部集成的手写体数字图片数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入手写体数字加载器,获得数码图像数据,每幅图片由8*8=64的像素矩阵表示\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "digits.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1347, 64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.25, random_state=33)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入标准化模块和基于线性假设的支持向量机分类器LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)\n",
    "\n",
    "lsvc = LinearSVC(max_iter=10000) # 报错ConvergenceWarning，模型未收敛，增加迭代次数\n",
    "lsvc.fit(X_train, y_train)\n",
    "y_predict = lsvc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LinearSVC is  0.9511111111111111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        35\n",
      "           1       0.95      0.98      0.96        54\n",
      "           2       0.98      1.00      0.99        44\n",
      "           3       0.93      0.93      0.93        46\n",
      "           4       0.97      1.00      0.99        35\n",
      "           5       0.94      0.94      0.94        48\n",
      "           6       0.96      0.98      0.97        51\n",
      "           7       0.92      1.00      0.96        35\n",
      "           8       0.98      0.83      0.90        58\n",
      "           9       0.95      0.91      0.93        44\n",
      "\n",
      "    accuracy                           0.95       450\n",
      "   macro avg       0.95      0.96      0.95       450\n",
      "weighted avg       0.95      0.95      0.95       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 评估\n",
    "from sklearn.metrics import classification_report\n",
    "print('Accuracy of LinearSVC is ', lsvc.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_predict, target_names=digits.target_names.astype(str)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.1.3 朴素贝叶斯\n",
    "##### 使用经典的20类新闻文本做文本分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18846\n",
      "From: Mamatha Devineni Ratnam <mr47+@andrew.cmu.edu>\n",
      "Subject: Pens fans reactions\n",
      "Organization: Post Office, Carnegie Mellon, Pittsburgh, PA\n",
      "Lines: 12\n",
      "NNTP-Posting-Host: po4.andrew.cmu.edu\n",
      "\n",
      "\n",
      "\n",
      "I am sure some bashers of Pens fans are pretty confused about the lack\n",
      "of any kind of posts about the recent Pens massacre of the Devils. Actually,\n",
      "I am  bit puzzled too and a bit relieved. However, I am going to put an end\n",
      "to non-PIttsburghers' relief with a bit of praise for the Pens. Man, they\n",
      "are killing those Devils worse than I thought. Jagr just showed you why\n",
      "he is much better than his regular season stats. He is also a lot\n",
      "fo fun to watch in the playoffs. Bowman should let JAgr have a lot of\n",
      "fun in the next couple of games since the Pens are going to beat the pulp out of Jersey anyway. I was very disappointed not to see the Islanders lose the final\n",
      "regular season game.          PENS RULE!!!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 获取新闻数据\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "news = fetch_20newsgroups(subset='all')\n",
    "print(len(news.data))\n",
    "print(news.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分割数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(news.data, news.target,test_size=0.25, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用朴素贝叶斯进行类别预测\n",
    "# 从feature_extraction.text里导入用于文本特征向量转化模块，只考虑词汇在文本出现的频率\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec = CountVectorizer()\n",
    "X_train = vec.fit_transform(X_train)\n",
    "X_test = vec.transform(X_test)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)\n",
    "y_predict = mnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy of NB is  0.8397707979626485\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.86      0.86      0.86       201\n",
      "           comp.graphics       0.59      0.86      0.70       250\n",
      " comp.os.ms-windows.misc       0.89      0.10      0.17       248\n",
      "comp.sys.ibm.pc.hardware       0.60      0.88      0.72       240\n",
      "   comp.sys.mac.hardware       0.93      0.78      0.85       242\n",
      "          comp.windows.x       0.82      0.84      0.83       263\n",
      "            misc.forsale       0.91      0.70      0.79       257\n",
      "               rec.autos       0.89      0.89      0.89       238\n",
      "         rec.motorcycles       0.98      0.92      0.95       276\n",
      "      rec.sport.baseball       0.98      0.91      0.95       251\n",
      "        rec.sport.hockey       0.93      0.99      0.96       233\n",
      "               sci.crypt       0.86      0.98      0.91       238\n",
      "         sci.electronics       0.85      0.88      0.86       249\n",
      "                 sci.med       0.92      0.94      0.93       245\n",
      "               sci.space       0.89      0.96      0.92       221\n",
      "  soc.religion.christian       0.78      0.96      0.86       232\n",
      "      talk.politics.guns       0.88      0.96      0.92       251\n",
      "   talk.politics.mideast       0.90      0.98      0.94       231\n",
      "      talk.politics.misc       0.79      0.89      0.84       188\n",
      "      talk.religion.misc       0.93      0.44      0.60       158\n",
      "\n",
      "                accuracy                           0.84      4712\n",
      "               macro avg       0.86      0.84      0.82      4712\n",
      "            weighted avg       0.86      0.84      0.82      4712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 性能评估\n",
    "from sklearn.metrics import classification_report\n",
    "print('The Accuracy of NB is ', mnb.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_predict, target_names=news.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.1.4 K近邻（分类）\n",
    "##### 利用K近邻对生物物种进行分类，鸢尾Iris数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入iris数据加载器，读取数据\n",
    "# 特征是4列花的形状长度宽度，最后一列是类别（150条，共3类）\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "iris.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "# 数据说明\n",
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分割数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.25, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 4)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5. , 2.3, 3.3, 1. ],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [5.1, 3.5, 1.4, 0.2],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [5.4, 3.4, 1.7, 0.2]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据标准化，使用K近邻进行类别预测\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knc = KNeighborsClassifier()\n",
    "knc.fit(X_train, y_train)\n",
    "y_predict = knc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy of KNC is  0.8947368421052632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00         8\n",
      "  versicolor       0.73      1.00      0.85        11\n",
      "   virginica       1.00      0.79      0.88        19\n",
      "\n",
      "    accuracy                           0.89        38\n",
      "   macro avg       0.91      0.93      0.91        38\n",
      "weighted avg       0.92      0.89      0.90        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 性能评估\n",
    "print('The Accuracy of KNC is ', knc.score(X_test, y_test))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_predict, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.1.5 决策树\n",
    "##### 使用决策树预测泰坦尼克号乘客的生还情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row.names</th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>embarked</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>room</th>\n",
       "      <th>ticket</th>\n",
       "      <th>boat</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>St Louis, MO</td>\n",
       "      <td>B-5</td>\n",
       "      <td>24160 L221</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(135)</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs Hudson J.C. (Bessie Waldo Daniels)</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master Hudson Trevor</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Anderson, Mr Harry</td>\n",
       "      <td>47.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>E-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Andrews, Miss Kornelia Theodosia</td>\n",
       "      <td>63.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Hudson, NY</td>\n",
       "      <td>D-7</td>\n",
       "      <td>13502 L77</td>\n",
       "      <td>10</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Andrews, Mr Thomas, jr</td>\n",
       "      <td>39.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Belfast, NI</td>\n",
       "      <td>A-36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Appleton, Mrs Edward Dale (Charlotte Lamson)</td>\n",
       "      <td>58.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Bayside, Queens, NY</td>\n",
       "      <td>C-101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Artagaveytia, Mr Ramon</td>\n",
       "      <td>71.0000</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>Montevideo, Uruguay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(22)</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Astor, Colonel John Jacob</td>\n",
       "      <td>47.0000</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17754 L224 10s 6d</td>\n",
       "      <td>(124)</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Astor, Mrs John Jacob (Madeleine Talmadge Force)</td>\n",
       "      <td>19.0000</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17754 L224 10s 6d</td>\n",
       "      <td>4</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Aubert, Mrs Leontine Pauline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>Paris, France</td>\n",
       "      <td>B-35</td>\n",
       "      <td>17477 L69 6s</td>\n",
       "      <td>9</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Barkworth, Mr Algernon H.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Hessle, Yorks</td>\n",
       "      <td>A-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Baumann, Mr John D.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Baxter, Mrs James (Helene DeLaudeniere Chaput)</td>\n",
       "      <td>50.0000</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>Montreal, PQ</td>\n",
       "      <td>B-58/60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Baxter, Mr Quigg Edmond</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>Montreal, PQ</td>\n",
       "      <td>B-58/60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Beattie, Mr Thomson</td>\n",
       "      <td>36.0000</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>Winnipeg, MN</td>\n",
       "      <td>C-6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Beckwith, Mr Richard Leonard</td>\n",
       "      <td>37.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>D-35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Beckwith, Mrs Richard Leonard (Sallie Monypeny)</td>\n",
       "      <td>47.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>D-35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr Karl Howell</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>C-148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Birnbaum, Mr Jakob</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(148)</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Bishop, Mr Dickinson H.</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>Dowagiac, MI</td>\n",
       "      <td>B-49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Bishop, Mrs Dickinson H. (Helen Walton)</td>\n",
       "      <td>19.0000</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>Dowagiac, MI</td>\n",
       "      <td>B-49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Bjornstrm-Steffansson, Mr Mauritz Hakan</td>\n",
       "      <td>28.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Stockholm, Sweden / Washington, DC</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Blackwell, Mr Stephen Weart</td>\n",
       "      <td>45.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Trenton, NJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(241)</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Blank, Mr Henry</td>\n",
       "      <td>39.0000</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>Glen Ridge, NJ</td>\n",
       "      <td>A-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss Caroline</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Youngstown, OH</td>\n",
       "      <td>C-7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss Elizabeth</td>\n",
       "      <td>58.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Birkdale, England Cleveland, Ohio</td>\n",
       "      <td>C-103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Borebank, Mr John James</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>London / Winnipeg, MB</td>\n",
       "      <td>D-21/2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>1284</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Vestrom, Miss Hulda Amanda Adolfina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>1285</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Vonk, Mr Jenko</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>1286</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Ware, Mr Frederick</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>1287</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Warren, Mr Charles William</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>1288</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Wazli, Mr Yousif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>1289</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Webber, Mr James</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>1290</td>\n",
       "      <td>3rd</td>\n",
       "      <td>1</td>\n",
       "      <td>Wennerstrom, Mr August Edvard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>1291</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Wenzel, Mr Linhart</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>1292</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Widegren, Mr Charles Peter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>1293</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Wiklund, Mr Jacob Alfred</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>1294</td>\n",
       "      <td>3rd</td>\n",
       "      <td>1</td>\n",
       "      <td>Wilkes, Mrs Ellen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>1295</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Willer, Mr Aaron</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>1296</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Willey, Mr Edward</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>1297</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Williams, Mr Howard Hugh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>1298</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Williams, Mr Leslie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>1299</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Windelov, Mr Einar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>1300</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Wirz, Mr Albert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>1301</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Wiseman, Mr Phillippe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>1302</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Wittevrongel, Mr Camiel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>1303</td>\n",
       "      <td>3rd</td>\n",
       "      <td>1</td>\n",
       "      <td>Yalsevac, Mr Ivan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>1304</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Yasbeck, Mr Antoni</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>1305</td>\n",
       "      <td>3rd</td>\n",
       "      <td>1</td>\n",
       "      <td>Yasbeck, Mrs Antoni</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>1306</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Youssef, Mr Gerios</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>1307</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Zabour, Miss Hileni</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>1308</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Zabour, Miss Tamini</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>1309</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Zakarian, Mr Artun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>1310</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Zakarian, Mr Maprieder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>1311</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Zenn, Mr Philip</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>1312</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Zievens, Rene</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>1313</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Zimmerman, Leo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1313 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      row.names pclass  survived  \\\n",
       "0             1    1st         1   \n",
       "1             2    1st         0   \n",
       "2             3    1st         0   \n",
       "3             4    1st         0   \n",
       "4             5    1st         1   \n",
       "5             6    1st         1   \n",
       "6             7    1st         1   \n",
       "7             8    1st         0   \n",
       "8             9    1st         1   \n",
       "9            10    1st         0   \n",
       "10           11    1st         0   \n",
       "11           12    1st         1   \n",
       "12           13    1st         1   \n",
       "13           14    1st         1   \n",
       "14           15    1st         0   \n",
       "15           16    1st         1   \n",
       "16           17    1st         0   \n",
       "17           18    1st         0   \n",
       "18           19    1st         1   \n",
       "19           20    1st         1   \n",
       "20           21    1st         1   \n",
       "21           22    1st         0   \n",
       "22           23    1st         1   \n",
       "23           24    1st         1   \n",
       "24           25    1st         1   \n",
       "25           26    1st         0   \n",
       "26           27    1st         1   \n",
       "27           28    1st         1   \n",
       "28           29    1st         1   \n",
       "29           30    1st         0   \n",
       "...         ...    ...       ...   \n",
       "1283       1284    3rd         0   \n",
       "1284       1285    3rd         0   \n",
       "1285       1286    3rd         0   \n",
       "1286       1287    3rd         0   \n",
       "1287       1288    3rd         0   \n",
       "1288       1289    3rd         0   \n",
       "1289       1290    3rd         1   \n",
       "1290       1291    3rd         0   \n",
       "1291       1292    3rd         0   \n",
       "1292       1293    3rd         0   \n",
       "1293       1294    3rd         1   \n",
       "1294       1295    3rd         0   \n",
       "1295       1296    3rd         0   \n",
       "1296       1297    3rd         0   \n",
       "1297       1298    3rd         0   \n",
       "1298       1299    3rd         0   \n",
       "1299       1300    3rd         0   \n",
       "1300       1301    3rd         0   \n",
       "1301       1302    3rd         0   \n",
       "1302       1303    3rd         1   \n",
       "1303       1304    3rd         0   \n",
       "1304       1305    3rd         1   \n",
       "1305       1306    3rd         0   \n",
       "1306       1307    3rd         0   \n",
       "1307       1308    3rd         0   \n",
       "1308       1309    3rd         0   \n",
       "1309       1310    3rd         0   \n",
       "1310       1311    3rd         0   \n",
       "1311       1312    3rd         0   \n",
       "1312       1313    3rd         0   \n",
       "\n",
       "                                                  name      age     embarked  \\\n",
       "0                         Allen, Miss Elisabeth Walton  29.0000  Southampton   \n",
       "1                          Allison, Miss Helen Loraine   2.0000  Southampton   \n",
       "2                  Allison, Mr Hudson Joshua Creighton  30.0000  Southampton   \n",
       "3      Allison, Mrs Hudson J.C. (Bessie Waldo Daniels)  25.0000  Southampton   \n",
       "4                        Allison, Master Hudson Trevor   0.9167  Southampton   \n",
       "5                                   Anderson, Mr Harry  47.0000  Southampton   \n",
       "6                     Andrews, Miss Kornelia Theodosia  63.0000  Southampton   \n",
       "7                               Andrews, Mr Thomas, jr  39.0000  Southampton   \n",
       "8         Appleton, Mrs Edward Dale (Charlotte Lamson)  58.0000  Southampton   \n",
       "9                               Artagaveytia, Mr Ramon  71.0000    Cherbourg   \n",
       "10                           Astor, Colonel John Jacob  47.0000    Cherbourg   \n",
       "11    Astor, Mrs John Jacob (Madeleine Talmadge Force)  19.0000    Cherbourg   \n",
       "12                        Aubert, Mrs Leontine Pauline      NaN    Cherbourg   \n",
       "13                           Barkworth, Mr Algernon H.      NaN  Southampton   \n",
       "14                                 Baumann, Mr John D.      NaN  Southampton   \n",
       "15      Baxter, Mrs James (Helene DeLaudeniere Chaput)  50.0000    Cherbourg   \n",
       "16                             Baxter, Mr Quigg Edmond  24.0000    Cherbourg   \n",
       "17                                 Beattie, Mr Thomson  36.0000    Cherbourg   \n",
       "18                        Beckwith, Mr Richard Leonard  37.0000  Southampton   \n",
       "19     Beckwith, Mrs Richard Leonard (Sallie Monypeny)  47.0000  Southampton   \n",
       "20                                Behr, Mr Karl Howell  26.0000    Cherbourg   \n",
       "21                                  Birnbaum, Mr Jakob  25.0000    Cherbourg   \n",
       "22                             Bishop, Mr Dickinson H.  25.0000    Cherbourg   \n",
       "23             Bishop, Mrs Dickinson H. (Helen Walton)  19.0000    Cherbourg   \n",
       "24             Bjornstrm-Steffansson, Mr Mauritz Hakan  28.0000  Southampton   \n",
       "25                         Blackwell, Mr Stephen Weart  45.0000  Southampton   \n",
       "26                                     Blank, Mr Henry  39.0000    Cherbourg   \n",
       "27                              Bonnell, Miss Caroline  30.0000  Southampton   \n",
       "28                             Bonnell, Miss Elizabeth  58.0000  Southampton   \n",
       "29                             Borebank, Mr John James      NaN  Southampton   \n",
       "...                                                ...      ...          ...   \n",
       "1283               Vestrom, Miss Hulda Amanda Adolfina      NaN          NaN   \n",
       "1284                                    Vonk, Mr Jenko      NaN          NaN   \n",
       "1285                                Ware, Mr Frederick      NaN          NaN   \n",
       "1286                        Warren, Mr Charles William      NaN          NaN   \n",
       "1287                                  Wazli, Mr Yousif      NaN          NaN   \n",
       "1288                                  Webber, Mr James      NaN          NaN   \n",
       "1289                     Wennerstrom, Mr August Edvard      NaN          NaN   \n",
       "1290                                Wenzel, Mr Linhart      NaN          NaN   \n",
       "1291                        Widegren, Mr Charles Peter      NaN          NaN   \n",
       "1292                          Wiklund, Mr Jacob Alfred      NaN          NaN   \n",
       "1293                                 Wilkes, Mrs Ellen      NaN          NaN   \n",
       "1294                                  Willer, Mr Aaron      NaN          NaN   \n",
       "1295                                 Willey, Mr Edward      NaN          NaN   \n",
       "1296                          Williams, Mr Howard Hugh      NaN          NaN   \n",
       "1297                               Williams, Mr Leslie      NaN          NaN   \n",
       "1298                                Windelov, Mr Einar      NaN          NaN   \n",
       "1299                                   Wirz, Mr Albert      NaN          NaN   \n",
       "1300                             Wiseman, Mr Phillippe      NaN          NaN   \n",
       "1301                           Wittevrongel, Mr Camiel      NaN          NaN   \n",
       "1302                                 Yalsevac, Mr Ivan      NaN          NaN   \n",
       "1303                                Yasbeck, Mr Antoni      NaN          NaN   \n",
       "1304                               Yasbeck, Mrs Antoni      NaN          NaN   \n",
       "1305                                Youssef, Mr Gerios      NaN          NaN   \n",
       "1306                               Zabour, Miss Hileni      NaN          NaN   \n",
       "1307                               Zabour, Miss Tamini      NaN          NaN   \n",
       "1308                                Zakarian, Mr Artun      NaN          NaN   \n",
       "1309                            Zakarian, Mr Maprieder      NaN          NaN   \n",
       "1310                                   Zenn, Mr Philip      NaN          NaN   \n",
       "1311                                     Zievens, Rene      NaN          NaN   \n",
       "1312                                    Zimmerman, Leo      NaN          NaN   \n",
       "\n",
       "                               home.dest     room             ticket   boat  \\\n",
       "0                           St Louis, MO      B-5         24160 L221      2   \n",
       "1        Montreal, PQ / Chesterville, ON      C26                NaN    NaN   \n",
       "2        Montreal, PQ / Chesterville, ON      C26                NaN  (135)   \n",
       "3        Montreal, PQ / Chesterville, ON      C26                NaN    NaN   \n",
       "4        Montreal, PQ / Chesterville, ON      C22                NaN     11   \n",
       "5                           New York, NY     E-12                NaN      3   \n",
       "6                             Hudson, NY      D-7          13502 L77     10   \n",
       "7                            Belfast, NI     A-36                NaN    NaN   \n",
       "8                    Bayside, Queens, NY    C-101                NaN      2   \n",
       "9                    Montevideo, Uruguay      NaN                NaN   (22)   \n",
       "10                          New York, NY      NaN  17754 L224 10s 6d  (124)   \n",
       "11                          New York, NY      NaN  17754 L224 10s 6d      4   \n",
       "12                         Paris, France     B-35       17477 L69 6s      9   \n",
       "13                         Hessle, Yorks     A-23                NaN      B   \n",
       "14                          New York, NY      NaN                NaN    NaN   \n",
       "15                          Montreal, PQ  B-58/60                NaN      6   \n",
       "16                          Montreal, PQ  B-58/60                NaN    NaN   \n",
       "17                          Winnipeg, MN      C-6                NaN    NaN   \n",
       "18                          New York, NY     D-35                NaN      5   \n",
       "19                          New York, NY     D-35                NaN      5   \n",
       "20                          New York, NY    C-148                NaN      5   \n",
       "21                     San Francisco, CA      NaN                NaN  (148)   \n",
       "22                          Dowagiac, MI     B-49                NaN      7   \n",
       "23                          Dowagiac, MI     B-49                NaN      7   \n",
       "24    Stockholm, Sweden / Washington, DC      NaN                         D   \n",
       "25                           Trenton, NJ      NaN                NaN  (241)   \n",
       "26                        Glen Ridge, NJ     A-31                NaN      7   \n",
       "27                        Youngstown, OH      C-7                NaN      8   \n",
       "28     Birkdale, England Cleveland, Ohio    C-103                NaN      8   \n",
       "29                 London / Winnipeg, MB   D-21/2                NaN    NaN   \n",
       "...                                  ...      ...                ...    ...   \n",
       "1283                                 NaN      NaN                NaN    NaN   \n",
       "1284                                 NaN      NaN                NaN    NaN   \n",
       "1285                                 NaN      NaN                NaN    NaN   \n",
       "1286                                 NaN      NaN                NaN    NaN   \n",
       "1287                                 NaN      NaN                NaN    NaN   \n",
       "1288                                 NaN      NaN                NaN    NaN   \n",
       "1289                                 NaN      NaN                NaN    NaN   \n",
       "1290                                 NaN      NaN                NaN    NaN   \n",
       "1291                                 NaN      NaN                NaN    NaN   \n",
       "1292                                 NaN      NaN                NaN    NaN   \n",
       "1293                                 NaN      NaN                NaN    NaN   \n",
       "1294                                 NaN      NaN                NaN    NaN   \n",
       "1295                                 NaN      NaN                NaN    NaN   \n",
       "1296                                 NaN      NaN                NaN    NaN   \n",
       "1297                                 NaN      NaN                NaN    NaN   \n",
       "1298                                 NaN      NaN                NaN    NaN   \n",
       "1299                                 NaN      NaN                NaN    NaN   \n",
       "1300                                 NaN      NaN                NaN    NaN   \n",
       "1301                                 NaN      NaN                NaN    NaN   \n",
       "1302                                 NaN      NaN                NaN    NaN   \n",
       "1303                                 NaN      NaN                NaN    NaN   \n",
       "1304                                 NaN      NaN                NaN    NaN   \n",
       "1305                                 NaN      NaN                NaN    NaN   \n",
       "1306                                 NaN      NaN                NaN    NaN   \n",
       "1307                                 NaN      NaN                NaN    NaN   \n",
       "1308                                 NaN      NaN                NaN    NaN   \n",
       "1309                                 NaN      NaN                NaN    NaN   \n",
       "1310                                 NaN      NaN                NaN    NaN   \n",
       "1311                                 NaN      NaN                NaN    NaN   \n",
       "1312                                 NaN      NaN                NaN    NaN   \n",
       "\n",
       "         sex  \n",
       "0     female  \n",
       "1     female  \n",
       "2       male  \n",
       "3     female  \n",
       "4       male  \n",
       "5       male  \n",
       "6     female  \n",
       "7       male  \n",
       "8     female  \n",
       "9       male  \n",
       "10      male  \n",
       "11    female  \n",
       "12    female  \n",
       "13      male  \n",
       "14      male  \n",
       "15    female  \n",
       "16      male  \n",
       "17      male  \n",
       "18      male  \n",
       "19    female  \n",
       "20      male  \n",
       "21      male  \n",
       "22      male  \n",
       "23    female  \n",
       "24      male  \n",
       "25      male  \n",
       "26      male  \n",
       "27    female  \n",
       "28    female  \n",
       "29      male  \n",
       "...      ...  \n",
       "1283  female  \n",
       "1284    male  \n",
       "1285    male  \n",
       "1286    male  \n",
       "1287    male  \n",
       "1288    male  \n",
       "1289    male  \n",
       "1290    male  \n",
       "1291    male  \n",
       "1292    male  \n",
       "1293  female  \n",
       "1294    male  \n",
       "1295    male  \n",
       "1296    male  \n",
       "1297    male  \n",
       "1298    male  \n",
       "1299    male  \n",
       "1300    male  \n",
       "1301    male  \n",
       "1302    male  \n",
       "1303    male  \n",
       "1304  female  \n",
       "1305    male  \n",
       "1306  female  \n",
       "1307  female  \n",
       "1308    male  \n",
       "1309    male  \n",
       "1310    male  \n",
       "1311  female  \n",
       "1312    male  \n",
       "\n",
       "[1313 rows x 11 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入数据\n",
    "import pandas as pd\n",
    "titanic = pd.read_csv('http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic.txt')\n",
    "titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1313 entries, 0 to 1312\n",
      "Data columns (total 11 columns):\n",
      "row.names    1313 non-null int64\n",
      "pclass       1313 non-null object\n",
      "survived     1313 non-null int64\n",
      "name         1313 non-null object\n",
      "age          633 non-null float64\n",
      "embarked     821 non-null object\n",
      "home.dest    754 non-null object\n",
      "room         77 non-null object\n",
      "ticket       69 non-null object\n",
      "boat         347 non-null object\n",
      "sex          1313 non-null object\n",
      "dtypes: float64(1), int64(2), object(8)\n",
      "memory usage: 112.9+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1313 entries, 0 to 1312\n",
      "Data columns (total 3 columns):\n",
      "pclass    1313 non-null object\n",
      "age       633 non-null float64\n",
      "sex       1313 non-null object\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 30.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# 基于背景知识做特征选择\n",
    "X = titanic[['pclass', 'age', 'sex']]\n",
    "y = titanic['survived']\n",
    "\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1313 entries, 0 to 1312\n",
      "Data columns (total 3 columns):\n",
      "pclass    1313 non-null object\n",
      "age       1313 non-null float64\n",
      "sex       1313 non-null object\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 30.9+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/pandas/core/generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "# 基于info，进行数据预处理\n",
    "# 1)age数据列只有633条数据，需要补全\n",
    "# 2）pclass和sex是类别型，需要转化为数值特征 0/1 表示\n",
    "\n",
    "# age补充，使用中位数或平均数，对模型偏离造成的影响较小\n",
    "X['age'].fillna(X['age'].mean(), inplace=True)\n",
    "\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'pclass=1st', 'pclass=2nd', 'pclass=3rd', 'sex=female', 'sex=male']\n"
     ]
    }
   ],
   "source": [
    "# 进行特征转换\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "vec = DictVectorizer(sparse=False)\n",
    "\n",
    "# 转换特征后，所有类别型特征都单独剥离出来，独成一列特征，数值型的则保持不变\n",
    "X_train = vec.fit_transform(X_train.to_dict(orient='record'))\n",
    "print(vec.feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31.19418104,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "         1.        ],\n",
       "       [31.19418104,  1.        ,  0.        ,  0.        ,  1.        ,\n",
       "         0.        ],\n",
       "       [31.19418104,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "         1.        ],\n",
       "       ...,\n",
       "       [12.        ,  0.        ,  1.        ,  0.        ,  1.        ,\n",
       "         0.        ],\n",
       "       [18.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "         1.        ],\n",
       "       [31.19418104,  0.        ,  0.        ,  1.        ,  1.        ,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 特征提取后，对应的属性下面为1，其余为0\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试集也要特征转换\n",
    "X_test = vec.transform(X_test.to_dict(orient='record'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用决策树进行预测\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_train, y_train)\n",
    "y_predict = dtc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy of dtc is  0.7811550151975684\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        died       0.78      0.91      0.84       202\n",
      "    survived       0.80      0.58      0.67       127\n",
      "\n",
      "    accuracy                           0.78       329\n",
      "   macro avg       0.79      0.74      0.75       329\n",
      "weighted avg       0.78      0.78      0.77       329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 性能评估\n",
    "from sklearn.metrics import classification_report\n",
    "print('The Accuracy of dtc is ', dtc.score(X_test, y_test))\n",
    "\n",
    "print(classification_report(y_test, y_predict, target_names=['died', 'survived']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.1.6 集成模型（分类）\n",
    "##### 利用单一决策树、随机森林分类以及梯度上升决策树对泰坦尼克进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/pandas/core/generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "titanic = pd.read_csv('http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic.txt')\n",
    "X = titanic[['age', 'pclass', 'sex']]\n",
    "y = titanic['survived']\n",
    "X['age'].fillna(X['age'].mean(), inplace=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=33)\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "vec = DictVectorizer()\n",
    "X_train = vec.fit_transform(X_train.to_dict(orient='record'))\n",
    "X_test = vec.transform(X_test.to_dict(orient='record'))\n",
    "\n",
    "# 单一决策树\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_train, y_train)\n",
    "dtc_y_predict = dtc.predict(X_test)\n",
    "\n",
    "# 随机森林分类器\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "rfc_y_predict = rfc.predict(X_test)\n",
    "\n",
    "# 梯度提升决策树\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier()\n",
    "gbc.fit(X_train, y_train)\n",
    "gbc_y_predict = gbc.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of dtc is  0.7811550151975684\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.91      0.84       202\n",
      "           1       0.80      0.58      0.67       127\n",
      "\n",
      "    accuracy                           0.78       329\n",
      "   macro avg       0.79      0.74      0.75       329\n",
      "weighted avg       0.78      0.78      0.77       329\n",
      "\n",
      "The accuracy of rfc is  0.78419452887538\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.91      0.84       202\n",
      "           1       0.80      0.59      0.68       127\n",
      "\n",
      "    accuracy                           0.78       329\n",
      "   macro avg       0.79      0.75      0.76       329\n",
      "weighted avg       0.79      0.78      0.78       329\n",
      "\n",
      "The accuracy of gbc is  0.790273556231003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.92      0.84       202\n",
      "           1       0.82      0.58      0.68       127\n",
      "\n",
      "    accuracy                           0.79       329\n",
      "   macro avg       0.80      0.75      0.76       329\n",
      "weighted avg       0.80      0.79      0.78       329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 性能评估\n",
    "from sklearn.metrics import classification_report\n",
    "print('The accuracy of dtc is ', dtc.score(X_test, y_test))\n",
    "print(classification_report(y_test, dtc_y_predict))\n",
    "\n",
    "print('The accuracy of rfc is ', rfc.score(X_test, y_test))\n",
    "print(classification_report(y_test, rfc_y_predict))\n",
    "\n",
    "print('The accuracy of gbc is ', gbc.score(X_test, y_test))\n",
    "print(classification_report(y_test, gbc_y_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}