{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性回归输出的是一个连续值，适用于回归问题。\n",
    "\n",
    "场景：预测房屋价格、气温、销售额等连续值问题。\n",
    "\n",
    "分类问题中模型最终输出的是一个离散值，softmax回归适用于分类问题。\n",
    "\n",
    "场景：图像分类、垃圾邮件识别、疾病检测等。\n",
    "\n",
    "**线性回归和softmax回归都是单层神经网络，涉及的概念和技术同样适用于大多数深度学习模型**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 线性回归的基本要素"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1.1 模型定义\n",
    "\n",
    "设房屋面积x1，房龄x2，售出价格为y\n",
    "\n",
    "y = x1w1 + x2w2 + b\n",
    "\n",
    "w1和w2是权重，b是偏差，均为标量。它们是线性回归模型的参数。\n",
    "\n",
    "y是线性回归对真实价格 y 的预测或估计。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1.2 模型训练\n",
    "通过数据来寻找特定的模型参数值，使模型在数据上的误差尽可能小。\n",
    "\n",
    "（1）训练数据\n",
    "\n",
    "训练集：真实的售出价格、面积和房龄数据。\n",
    "\n",
    "样本：一栋房屋\n",
    "\n",
    "标签：真实售出价格\n",
    "\n",
    "特征：用来预测标签的两个因素，用来表征样本的特点\n",
    "\n",
    "（2）损失函数\n",
    "\n",
    "在模型训练中，需要衡量价格预测值与真实值之间的误差，通常选取一个非负数作为误差。\n",
    "\n",
    "**一个常用的选择是：平方函数**\n",
    "\n",
    "这个误差只与模型参数相关，所以将它记为以模型参数为参数的函数。\n",
    "\n",
    "损失函数：衡量误差的函数\n",
    "\n",
    "平方损失：使用平方误差函数\n",
    "\n",
    "（3）优化算法\n",
    "\n",
    "解析解：可以直接用公式表达出来的误差最小化问题的解\n",
    "\n",
    "数值解：（大多数神学习模型并没有解析解）通过优化算法有限次迭代模型参数来尽可能降低损失函数的值\n",
    "\n",
    "求数值解的优化算法中，**小批量随机梯度下降** 被广泛使用。\n",
    "\n",
    "\n",
    "**批量次数** 和 **学习率** 是超参数，需要人为设定。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1.3 模型预测\n",
    "\n",
    "用得到的函数，进行预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 线性回归的表示方法\n",
    "\n",
    "#### 3.1.2.1 神经网络图\n",
    "\n",
    "神经网络图隐去了模型参数权重和偏差。\n",
    "\n",
    "单层神经网络：神经网络层数为1.\n",
    "\n",
    "神经元：输出层中负责计算o的单元\n",
    "\n",
    "全连接层（稠密层）：输出层中的神经元和输入层中各个输入完全连接"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2.2 矢量计算表达式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from time import time\n",
    "\n",
    "a = torch.ones(1000)\n",
    "b = torch.ones(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007102251052856445\n"
     ]
    }
   ],
   "source": [
    "# 方法一：将这两个向量按元素逐一按标量相加\n",
    "start = time()\n",
    "c = torch.zeros(1000)\n",
    "for i in range(1000):\n",
    "    c[i] = a[i] + b[i]\n",
    "print(time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0008349418640136719\n"
     ]
    }
   ],
   "source": [
    "# 方法二：直接坐矢量加法（效率更高）\n",
    "start = time()\n",
    "d = a + b\n",
    "print(time() - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
