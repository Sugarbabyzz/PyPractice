{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.Tensor` 是存储和变换数据的主要工具。\n",
    "\n",
    "`Tensor` 与 NumPy 的多维数组非常类似，但 `Tensor` 提供GPU计算和自动求梯度等更多功能，更加适合深度学习。\n",
    "\n",
    "`Tensor` 即为”张量“，可以看做为一个多维数据。\n",
    "\n",
    "> 标量可以看作是0维张量，向量可以看作1维张量，矩阵可以看作二维张量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 创建`Tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.2351e+12, 3.0945e-41, 0.0000e+00],\n",
      "        [0.0000e+00, 4.2344e+12, 3.0945e-41],\n",
      "        [4.2344e+12, 3.0945e-41, 4.2344e+12],\n",
      "        [3.0945e-41, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# 创建未初始化的tensor\n",
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6387, 0.3633, 0.6102],\n",
      "        [0.3081, 0.9135, 0.9624],\n",
      "        [0.2534, 0.1341, 0.5390],\n",
      "        [0.4373, 0.5965, 0.9568],\n",
      "        [0.0874, 0.0692, 0.2635]])\n"
     ]
    }
   ],
   "source": [
    "# 创建随机初始化的tensor\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# 创建long型全0的tensor\n",
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "# 直接根据数据创建tensor\n",
    "x = torch.tensor([5.5, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[ 0.1496,  0.1086,  1.3319],\n",
      "        [ 1.5724, -1.4965,  0.4204],\n",
      "        [-0.3620,  1.0855,  0.2206],\n",
      "        [ 0.3139,  1.3442,  3.0412],\n",
      "        [-0.4156,  0.6823, -0.2777]])\n"
     ]
    }
   ],
   "source": [
    "# 通过现有的tensor创建，会默认重用输入tensor的属性，如数据类型\n",
    "x = x.new_ones(5, 3, dtype=torch.float64)\n",
    "print(x)\n",
    "\n",
    "x = torch.randn_like(x, dtype=torch.float)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "<class 'torch.Size'>\n",
      "torch.Size([5, 3])\n",
      "<class 'torch.Size'>\n"
     ]
    }
   ],
   "source": [
    "# 获取tensor的形状，torch.Size其实是个tuple，支持所有tuple操作\n",
    "print(x.size())\n",
    "print(type(x.size()))\n",
    "print(x.shape)\n",
    "print(type(x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 算术操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6848,  0.5394,  2.2371],\n",
      "        [ 1.6719, -0.6280,  0.4771],\n",
      "        [ 0.4528,  1.4676,  0.9897],\n",
      "        [ 0.6461,  1.4832,  3.2895],\n",
      "        [ 0.0416,  1.3725, -0.1802]])\n",
      "tensor([[ 0.6848,  0.5394,  2.2371],\n",
      "        [ 1.6719, -0.6280,  0.4771],\n",
      "        [ 0.4528,  1.4676,  0.9897],\n",
      "        [ 0.6461,  1.4832,  3.2895],\n",
      "        [ 0.0416,  1.3725, -0.1802]])\n",
      "tensor([[ 0.6848,  0.5394,  2.2371],\n",
      "        [ 1.6719, -0.6280,  0.4771],\n",
      "        [ 0.4528,  1.4676,  0.9897],\n",
      "        [ 0.6461,  1.4832,  3.2895],\n",
      "        [ 0.0416,  1.3725, -0.1802]])\n",
      "tensor([[ 0.6848,  0.5394,  2.2371],\n",
      "        [ 1.6719, -0.6280,  0.4771],\n",
      "        [ 0.4528,  1.4676,  0.9897],\n",
      "        [ 0.6461,  1.4832,  3.2895],\n",
      "        [ 0.0416,  1.3725, -0.1802]])\n"
     ]
    }
   ],
   "source": [
    "# 加法\n",
    "# 形式一\n",
    "y = torch.rand(5, 3)\n",
    "print(x + y)\n",
    "\n",
    "# 形式二\n",
    "print(torch.add(x, y))\n",
    "# 还可以指定输出对象\n",
    "result = torch.empty(5, 3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)\n",
    "\n",
    "# 形式三\n",
    "# PyTorch操作inplace版本都有后缀 _，例如 x.copy_(y)、x.t_()\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 索引\n",
    "\n",
    "通过索引操作来访问 tensor 的一部分。\n",
    "\n",
    "**索引出来的结果与原数据共享内存，即一个修改，另一个会跟着修改**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1496,  0.1086,  1.3319],\n",
      "        [ 1.5724, -1.4965,  0.4204],\n",
      "        [-0.3620,  1.0855,  0.2206],\n",
      "        [ 0.3139,  1.3442,  3.0412],\n",
      "        [-0.4156,  0.6823, -0.2777]])\n",
      "tensor([1.1496, 1.1086, 2.3319])\n",
      "tensor([[ 1.1496,  1.1086,  2.3319],\n",
      "        [ 1.5724, -1.4965,  0.4204],\n",
      "        [-0.3620,  1.0855,  0.2206],\n",
      "        [ 0.3139,  1.3442,  3.0412],\n",
      "        [-0.4156,  0.6823, -0.2777]])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "y = x[0, :]  # 第0行的所有列\n",
    "y += 1\n",
    "print(y)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1496,  1.1086,  2.3319],\n",
      "        [-0.3620,  1.0855,  0.2206]])\n",
      "tensor([[ 1.1086,  2.3319],\n",
      "        [-1.4965,  0.4204],\n",
      "        [ 1.0855,  0.2206],\n",
      "        [ 1.3442,  3.0412],\n",
      "        [ 0.6823, -0.2777]])\n"
     ]
    }
   ],
   "source": [
    "# index_select（输入，维度，行/列索引）\n",
    "print(torch.index_select(x, 0, torch.tensor([0, 2])))\n",
    "print(torch.index_select(x, 1, torch.tensor([1, 2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 改变形状\n",
    "\n",
    "view() 返回的新 tensor 与源 tensor 虽然可能有不同的 size，但是共享 data！即修改一个，另一个也跟着改变。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1496,  1.1086,  2.3319],\n",
      "        [ 1.5724, -1.4965,  0.4204],\n",
      "        [-0.3620,  1.0855,  0.2206],\n",
      "        [ 0.3139,  1.3442,  3.0412],\n",
      "        [-0.4156,  0.6823, -0.2777]])\n",
      "tensor([ 1.1496,  1.1086,  2.3319,  1.5724, -1.4965,  0.4204, -0.3620,  1.0855,\n",
      "         0.2206,  0.3139,  1.3442,  3.0412, -0.4156,  0.6823, -0.2777])\n",
      "tensor([[ 1.1496,  1.1086,  2.3319,  1.5724, -1.4965],\n",
      "        [ 0.4204, -0.3620,  1.0855,  0.2206,  0.3139],\n",
      "        [ 1.3442,  3.0412, -0.4156,  0.6823, -0.2777]])\n"
     ]
    }
   ],
   "source": [
    "# 用view()改变形状\n",
    "y = x.view(15)\n",
    "z = x.view(-1, 5) # -1所指的维度可以根据其他维度的值推出来\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.1496,  1.1086,  2.3319,  1.5724, -1.4965,  0.4204, -0.3620,  1.0855,\n",
      "         0.2206,  0.3139,  1.3442,  3.0412, -0.4156,  0.6823, -0.2777])\n",
      "tensor([[ 1.1496,  1.1086,  2.3319],\n",
      "        [ 1.5724, -1.4965,  0.4204],\n",
      "        [-0.3620,  1.0855,  0.2206],\n",
      "        [ 0.3139,  1.3442,  3.0412],\n",
      "        [-0.4156,  0.6823, -0.2777]])\n"
     ]
    }
   ],
   "source": [
    "# 数据共享\n",
    "y += 1\n",
    "print(y)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果不想共享数据，可以利用 `replace()` 改变形状，但此函数并不能保证返回的是其拷贝，所以不推荐使用！\n",
    "\n",
    "推荐使用：先用 `clone()` 创造一个副本，然后再使用 `view`。\n",
    "\n",
    "使用 `clone` 还有一个好处，会被记录在计算图中，即梯度回传到副本时也会传到源 `Tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1496,  0.1086,  1.3319],\n",
      "        [ 0.5724, -2.4965, -0.5796],\n",
      "        [-1.3620,  0.0855, -0.7794],\n",
      "        [-0.6861,  0.3442,  2.0412],\n",
      "        [-1.4156, -0.3177, -1.2777]])\n",
      "tensor([ 1.1496,  1.1086,  2.3319,  1.5724, -1.4965,  0.4204, -0.3620,  1.0855,\n",
      "         0.2206,  0.3139,  1.3442,  3.0412, -0.4156,  0.6823, -0.2777])\n"
     ]
    }
   ],
   "source": [
    "x_cp = x.clone().view(15)\n",
    "x -= 1\n",
    "print(x)\n",
    "print(x_cp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`item()`：可以将标量`Tensor`转换成一个Python number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8719])\n",
      "0.8719181418418884\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 线性代数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "支持超过一百种操作，包括转置、索引、切片、数学运算、线性代数、随机数等，避免重复造轮子。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 广播机制\n",
    "\n",
    "对于两个形状不同的 tensor 按元素运算时，可能会触发广播机制。\n",
    "\n",
    "广播机制：先适当复制元素使这两个 `Tensor` 形状相同后再按元素运算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2]])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n",
      "tensor([[2, 3],\n",
      "        [3, 4],\n",
      "        [4, 5]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(1, 3).view(1, 2)\n",
    "y = torch.arange(1, 4).view(3, 1)\n",
    "print(x)\n",
    "print(y)\n",
    "print(x + y)\n",
    "# x中的第一行的两个元素被广播（复制）到第二和第三行\n",
    "# y中第一列的三个元素被广播（复制）到了第二列\n",
    "# 从而可以对两个3行2列的矩阵按元素相加了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4 运算的内存开销\n",
    "\n",
    "索引操作不会开辟新内存；但 `y = x + y`这样的运算会新开内存，然后将 y 指向新内存。\n",
    "\n",
    "`id`函数：如果两个实例的ID一致，那么它们所对应的内存地址相同，反之则不同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2])\n",
    "y = torch.tensor([3, 4])\n",
    "id_before = id(y)\n",
    "y = y + x\n",
    "print(id(y) == id_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# 如果想指定结果到原来 y 的内存，使用索引来进行替换操作\n",
    "id_before = id(y)\n",
    "y[:] = y + x\n",
    "print(id(y) == id_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 7, 12])\n"
     ]
    }
   ],
   "source": [
    "# 使用全名函数中的 out 参数或者自加运算符也可\n",
    "torch.add(x, y, out=y)\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.5 Tensor和NumPy相互转换\n",
    "\n",
    "可以用 `numpy()` 和 `from_numpy()` 将 Tensor 和 NumPy中的数组相互转换。\n",
    "\n",
    "**注意**：这两个函数所产生的 Tensor 和 NumPy中的数组共享相同的内存，改变其中一个另一个也会改变。\n",
    "\n",
    "> 将Numpy中的array转换成 Tensor 的方法就是 `torch.tensor()`，词方法总是会进行数据拷贝（消耗更多的时间合空间），返回的 `Tensor` 和原来的数据不再共享内存。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tensor 转 NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.]) <class 'torch.Tensor'>\n",
      "[1. 1. 1. 1. 1.] <class 'numpy.ndarray'>\n",
      "tensor([2., 2., 2., 2., 2.]) [2. 2. 2. 2. 2.]\n",
      "tensor([3., 3., 3., 3., 3.]) [3. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "b = a.numpy()\n",
    "print(a, type(a))\n",
    "print(b, type(b))\n",
    "a += 1\n",
    "print(a, b)\n",
    "b += 1\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NumPy数组 转 Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.] tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "[2. 2. 2. 2. 2.] tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "print(a, b)\n",
    "a += 1\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensor() 不再数据共享"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4. 4. 4. 4. 4.] tensor([3., 3., 3., 3., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "c = torch.tensor(a)\n",
    "a += 1\n",
    "print(a, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.6 Tensor on GPU\n",
    "\n",
    "`to()` 方法将 Tensor 在 CPU和GPU之间相互移动。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 3], device='cuda:0')\n",
      "tensor([2., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\") # GPU\n",
    "    y = torch.ones_like(x, device=device)  # 在GPU上创建一个Tensor\n",
    "    x = x.to(device)  # 等价于.to(\"cuda\")\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))  # to()还可以同时更改数据类型"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
